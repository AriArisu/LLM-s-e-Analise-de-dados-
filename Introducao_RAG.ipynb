{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upkiGoxE8OUA"
      },
      "source": [
        "# InteligÃªncia Artificial Generativa - RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB3av1jO8McX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9cf644bf-5bdb-4799-b7f7-07f005ac8517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m809.0/981.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.8/207.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#instalando bibliotecas\n",
        "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph langchain-openai langchain-core pypdf unstructured\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"unstructured[pdf]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pXoWNfc52Po6",
        "outputId": "3084b79a-ebc2-4363-97fb-04a6c74954ba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: unstructured[pdf] in /usr/local/lib/python3.12/dist-packages (0.18.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (3.4.3)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (3.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (2.32.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (4.13.5)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (2.14.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (2025.2.18)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (2.0.2)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (3.14.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (4.15.0)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (0.42.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (1.17.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (0.0.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (1.1)\n",
            "Collecting onnx>=1.17.0 (from unstructured[pdf])\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting onnxruntime>=1.19.0 (from unstructured[pdf])\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting pdf2image (from unstructured[pdf])\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pdfminer.six (from unstructured[pdf])\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pikepdf (from unstructured[pdf])\n",
            "  Downloading pikepdf-9.10.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pi-heif (from unstructured[pdf])\n",
            "  Downloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (from unstructured[pdf]) (6.0.0)\n",
            "Collecting google-cloud-vision (from unstructured[pdf])\n",
            "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting effdet (from unstructured[pdf])\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting unstructured-inference>=1.0.5 (from unstructured[pdf])\n",
            "  Downloading unstructured_inference-1.0.5-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
            "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.17.0->unstructured[pdf]) (5.29.5)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx>=1.17.0->unstructured[pdf]) (0.5.3)\n",
            "Collecting coloredlogs (from onnxruntime>=1.19.0->unstructured[pdf])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (25.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19.0->unstructured[pdf]) (1.13.3)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (0.0.20)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (0.34.4)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (2.8.0+cu126)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (1.0.19)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (4.55.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (1.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from unstructured-inference>=1.0.5->unstructured[pdf]) (1.16.1)\n",
            "Collecting pypdfium2 (from unstructured-inference>=1.0.5->unstructured[pdf])\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (11.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured[pdf]) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from effdet->unstructured[pdf]) (0.23.0+cu126)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from effdet->unstructured[pdf]) (2.0.10)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.12/dist-packages (from effdet->unstructured[pdf]) (2.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision->unstructured[pdf]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-vision->unstructured[pdf]) (1.26.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured[pdf]) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured[pdf]) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured[pdf]) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->unstructured[pdf]) (2024.11.6)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six->unstructured[pdf]) (43.0.3)\n",
            "Collecting Deprecated (from pikepdf->unstructured[pdf])\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.12/dist-packages (from python-oxmsg->unstructured[pdf]) (0.47)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured[pdf]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->unstructured[pdf]) (2025.8.3)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured[pdf]) (24.1.0)\n",
            "Requirement already satisfied: httpcore>=1.0.9 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.9)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured[pdf]) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured[pdf]) (2.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore>=1.0.9->unstructured-client->unstructured[pdf]) (0.16.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.10.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured[pdf]) (0.4.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->unstructured-inference>=1.0.5->unstructured[pdf]) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (75.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->unstructured-inference>=1.0.5->unstructured[pdf]) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.19.0->unstructured[pdf]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.25.1->unstructured-inference>=1.0.5->unstructured[pdf]) (0.21.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->unstructured-inference>=1.0.5->unstructured[pdf]) (1.1.8)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.1.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.19.0->unstructured[pdf])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->unstructured-inference>=1.0.5->unstructured[pdf]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->unstructured-inference>=1.0.5->unstructured[pdf]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->unstructured-inference>=1.0.5->unstructured[pdf]) (2025.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->unstructured-inference>=1.0.5->unstructured[pdf]) (3.0.2)\n",
            "Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_inference-1.0.5-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
            "Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.10.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unstructured.pytesseract, pypdfium2, pi-heif, pdf2image, humanfriendly, Deprecated, pikepdf, onnx, coloredlogs, pdfminer.six, onnxruntime, google-cloud-vision, unstructured-inference, effdet\n",
            "Successfully installed Deprecated-1.2.18 coloredlogs-15.0.1 effdet-0.4.1 google-cloud-vision-3.10.2 humanfriendly-10.0 onnx-1.19.0 onnxruntime-1.22.1 pdf2image-1.17.0 pdfminer.six-20250506 pi-heif-1.1.0 pikepdf-9.10.2 pypdfium2-4.30.0 unstructured-inference-1.0.5 unstructured.pytesseract-0.3.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "ff660cfa76534e43bab9eed6e4ae89e8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuuRpRkm8a5I"
      },
      "outputs": [],
      "source": [
        "# configurando chatgpt\n",
        "import getpass\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import UnstructuredURLLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDgwMn4r9Gdy"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwi9IDHA9Gaw",
        "outputId": "61019296-75bc-48d4-8a5e-fcd7f33dedc8",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O \"melhor\" chat de IA pode variar dependendo das suas necessidades especÃ­ficas. Algumas opÃ§Ãµes populares incluem:\n",
            "\n",
            "1. **ChatGPT** â€“ Desenvolvido pela OpenAI, Ã© conhecido pela sua fluÃªncia e capacidade de manter conversas coerentes em diversos tÃ³picos.\n",
            "   \n",
            "2. **Google Bard** â€“ Outro assistente de IA que busca fornecer informaÃ§Ãµes e respostas com base em dados da web.\n",
            "\n",
            "3. **Microsoft Copilot** â€“ Integrado em produtos do Microsoft 365, ajuda em tarefas de produtividade.\n",
            "\n",
            "4. **Claude** â€“ Desenvolvido pela Anthropic, busca proporcionar interaÃ§Ãµes de forma Ã©tica e segura.\n",
            "\n",
            "Cada um desses chats de IA pode ter pontos fortes diferentes, entÃ£o o melhor depende do que vocÃª estÃ¡ procurando: se Ã© uma conversa casual, auxÃ­lio em tarefas, respostas rÃ¡pidas a perguntas ou outra coisa. Experimente alguns deles para ver qual atende melhor Ã s suas necessidades!\n"
          ]
        }
      ],
      "source": [
        "#testando\n",
        "resposta = llm.invoke('qual Ã© o melhor chat de IA')\n",
        "print(resposta.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSpbPgPC9GYw"
      },
      "outputs": [],
      "source": [
        "#selecionando o embedding\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRf0QWWV9GW4"
      },
      "outputs": [],
      "source": [
        "vector_store = InMemoryVectorStore(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Conteudo***"
      ],
      "metadata": {
        "id": "3n3JlyfyvGoQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awdSGfVM9GUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d607ed42-cb98-4b3f-b7bf-477acf713c62",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P13' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P34' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P39' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P44' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P49' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P54' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P61' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P67' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P71' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P75' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P80' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P85' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P89' is an invalid float value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No languages specified, defaulting to English.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#criando uma base de cohecimento\n",
        "import bs4\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "\n",
        "loader = DirectoryLoader(\"/content/Pastinha\", glob=\"**/*.pdf\")\n",
        "docs = loader.load()\n",
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ju6VjVT-Hq_",
        "outputId": "a6a555a6-3b37-46d9-ae65-ab7a56b65930",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf'}, page_content='Large Language\\n\\nmodels\\n\\nRegressÃ£o LogÃ­stica â€“ A funÃ§Ã£o SigmÃ³ide\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRegressÃ£o LogÃ­stica â€“ Algoritmo Gradiente descendente\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRedes Neurais\\n\\nEntrada\\n\\nSaÃ­da\\n\\nA escala move a IA\\n\\nQuanto mais camadas a rede neural\\n\\npossui, mais complexas as funÃ§Ãµes\\n\\nmatemÃ¡ticas que ela pode aprender...\\n\\nA escala move a IA\\n\\n...quanto mais complexa a rede\\n\\nneural, mais dados sÃ£o necessÃ¡rios\\n\\npara ela aprender.\\n\\nA escala move a IA\\n\\nGPT-4\\n\\nRede Neural com +200 bilhÃµes de parÃ¢metros(!)\\n\\nTreinados com mais de 53 trilhÃµes de palavras(!)\\n\\n+3 meses de treinamento dos modelos\\n\\nUm investimento total de mais de $63 milhÃµes (!)\\n\\nLLMs e IA\\n\\ngenerativa\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nbolo\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nEu adoro comer bolo de\\n\\nchocolate\\n\\nQuando treinamos esse modelo de AI com muitos dados (centenas de bilhÃµes de palavras ) obtemos um Large Language Model que Ã© a base do ChatGPT\\n\\nTransformers\\n\\nLLM Tokenization Byte Pair Encodng(BPE)\\n\\nhttps://tiktokenizer.vercel.app/\\n\\nLLM Playground\\n\\nhttps://colab.research.google.com/drive/1BKq_MMCcYz1eYLQaAenGJyuvxXoLeNQa?usp=sharing\\n\\nExerÃ­cios\\n\\nLer o primeiro capÃ­tulo do livro:\\n\\nhttps://hastie.su.domains/ISLP/ISLP_website.pdf.download.html\\n\\nE fazer o LAB de Python a partir da pÃ¡gina 40.')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urls = [\n",
        "\n",
        "    \"https://developers.google.com/machine-learning/gan/generative?hl=pt-br\",\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "YS0iYECMwl_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieK2lmZz-hVH",
        "outputId": "92a92ae3-9621-4473-f499-67b9439fc5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split pdf into 3 sub-documents.\n"
          ]
        }
      ],
      "source": [
        "#fazendo o splitting dos documentos\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split pdf into {len(all_splits)} sub-documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KikWkMS7AXCv",
        "outputId": "087bc425-52b4-43fb-d77e-bca9cbbc5a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 0}, page_content='Large Language\\n\\nmodels\\n\\nRegressÃ£o LogÃ­stica â€“ A funÃ§Ã£o SigmÃ³ide\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRegressÃ£o LogÃ­stica â€“ Algoritmo Gradiente descendente\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRedes Neurais\\n\\nEntrada\\n\\nSaÃ­da\\n\\nA escala move a IA\\n\\nQuanto mais camadas a rede neural\\n\\npossui, mais complexas as funÃ§Ãµes\\n\\nmatemÃ¡ticas que ela pode aprender...\\n\\nA escala move a IA\\n\\n...quanto mais complexa a rede\\n\\nneural, mais dados sÃ£o necessÃ¡rios\\n\\npara ela aprender.\\n\\nA escala move a IA\\n\\nGPT-4\\n\\nRede Neural com +200 bilhÃµes de parÃ¢metros(!)\\n\\nTreinados com mais de 53 trilhÃµes de palavras(!)\\n\\n+3 meses de treinamento dos modelos\\n\\nUm investimento total de mais de $63 milhÃµes (!)\\n\\nLLMs e IA\\n\\ngenerativa\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "all_splits[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ooq18kAdNX",
        "outputId": "e05e1069-e44f-47da-c321-4c088541c772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['6fc79566-566b-480b-b1ad-46f9edae0c95', '2b33026c-48fe-4432-8b69-ffc612f65907', '0a52280c-12e8-4a0c-8992-04107bb60497']\n"
          ]
        }
      ],
      "source": [
        "#guardando os dados em um banco de dados\n",
        "document_ids = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "print(document_ids[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnQROsMXAh3X",
        "outputId": "ef1a00e6-0067-490e-97c0-a55b878fedee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "## recuperando informaÃ§Ãµes para ajudar o chatgpt\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbNrIrITAzv8"
      },
      "outputs": [],
      "source": [
        "# Como atualizar o prompt:\n",
        "\n",
        "prompt.messages[0].prompt.template = '''You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'NAO SEI'. Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaFh3V-gBe6B",
        "outputId": "ef8dec64-8e64-4fb5-f7dc-445a7dea48c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say 'NAO SEI'. Use three sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3Sac0zjBbAv"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vijJtfIdBmyv"
      },
      "outputs": [],
      "source": [
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu4yW7wFBoNf"
      },
      "outputs": [],
      "source": [
        "#definindo o fluxo de trabalho\n",
        "from langgraph.graph import START, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3eCm56RUBpzH",
        "outputId": "bb9394ad-6fba-4b23-e978-2417303623d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'display(Image(graph.get_graph().draw_mermaid_png()))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "'from IPython.display import Image, display'\n",
        "'display(Image(graph.get_graph().draw_mermaid_png()))'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCfNBCxxBuRQ",
        "outputId": "938c7922-e46a-4706-9492-dd92a2e15bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [Document(id='2b33026c-48fe-4432-8b69-ffc612f65907', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 821}, page_content='prompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nbolo\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano'), Document(id='6fc79566-566b-480b-b1ad-46f9edae0c95', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 0}, page_content='Large Language\\n\\nmodels\\n\\nRegressÃ£o LogÃ­stica â€“ A funÃ§Ã£o SigmÃ³ide\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRegressÃ£o LogÃ­stica â€“ Algoritmo Gradiente descendente\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRedes Neurais\\n\\nEntrada\\n\\nSaÃ­da\\n\\nA escala move a IA\\n\\nQuanto mais camadas a rede neural\\n\\npossui, mais complexas as funÃ§Ãµes\\n\\nmatemÃ¡ticas que ela pode aprender...\\n\\nA escala move a IA\\n\\n...quanto mais complexa a rede\\n\\nneural, mais dados sÃ£o necessÃ¡rios\\n\\npara ela aprender.\\n\\nA escala move a IA\\n\\nGPT-4\\n\\nRede Neural com +200 bilhÃµes de parÃ¢metros(!)\\n\\nTreinados com mais de 53 trilhÃµes de palavras(!)\\n\\n+3 meses de treinamento dos modelos\\n\\nUm investimento total de mais de $63 milhÃµes (!)\\n\\nLLMs e IA\\n\\ngenerativa\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA'), Document(id='0a52280c-12e8-4a0c-8992-04107bb60497', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 1572}, page_content='Processo geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nEu adoro comer bolo de\\n\\nchocolate\\n\\nQuando treinamos esse modelo de AI com muitos dados (centenas de bilhÃµes de palavras ) obtemos um Large Language Model que Ã© a base do ChatGPT\\n\\nTransformers\\n\\nLLM Tokenization Byte Pair Encodng(BPE)\\n\\nhttps://tiktokenizer.vercel.app/\\n\\nLLM Playground\\n\\nhttps://colab.research.google.com/drive/1BKq_MMCcYz1eYLQaAenGJyuvxXoLeNQa?usp=sharing\\n\\nExerÃ­cios\\n\\nLer o primeiro capÃ­tulo do livro:\\n\\nhttps://hastie.su.domains/ISLP/ISLP_website.pdf.download.html\\n\\nE fazer o LAB de Python a partir da pÃ¡gina 40.')]\n",
            "\n",
            "\n",
            "Answer: IA, ou InteligÃªncia Artificial, Ã© um campo da ciÃªncia da computaÃ§Ã£o que se concentra na criaÃ§Ã£o de sistemas capazes de realizar tarefas que normalmente exigem inteligÃªncia humana. A IA generativa, por sua vez, Ã© um tipo de IA que gera conteÃºdo, como texto ou imagens, utilizando modelos treinados em grandes volumes de dados. Um exemplo prÃ¡tico Ã© o uso de modelos de linguagem, como o ChatGPT.\n"
          ]
        }
      ],
      "source": [
        "result = graph.invoke({\"question\": \"o que Ã© ia?\"})\n",
        "\n",
        "print(f'Context: {result[\"context\"]}\\n\\n')\n",
        "print(f'Answer: {result[\"answer\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svmXBh4ABzGn",
        "outputId": "c78efe33-ff6b-4bfc-ce40-a260dfee51a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='2b33026c-48fe-4432-8b69-ffc612f65907', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 821}, page_content='prompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nbolo\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano'),\n",
              " Document(id='6fc79566-566b-480b-b1ad-46f9edae0c95', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 0}, page_content='Large Language\\n\\nmodels\\n\\nRegressÃ£o LogÃ­stica â€“ A funÃ§Ã£o SigmÃ³ide\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRegressÃ£o LogÃ­stica â€“ Algoritmo Gradiente descendente\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRedes Neurais\\n\\nEntrada\\n\\nSaÃ­da\\n\\nA escala move a IA\\n\\nQuanto mais camadas a rede neural\\n\\npossui, mais complexas as funÃ§Ãµes\\n\\nmatemÃ¡ticas que ela pode aprender...\\n\\nA escala move a IA\\n\\n...quanto mais complexa a rede\\n\\nneural, mais dados sÃ£o necessÃ¡rios\\n\\npara ela aprender.\\n\\nA escala move a IA\\n\\nGPT-4\\n\\nRede Neural com +200 bilhÃµes de parÃ¢metros(!)\\n\\nTreinados com mais de 53 trilhÃµes de palavras(!)\\n\\n+3 meses de treinamento dos modelos\\n\\nUm investimento total de mais de $63 milhÃµes (!)\\n\\nLLMs e IA\\n\\ngenerativa\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA'),\n",
              " Document(id='0a52280c-12e8-4a0c-8992-04107bb60497', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 1572}, page_content='Processo geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nEu adoro comer bolo de\\n\\nchocolate\\n\\nQuando treinamos esse modelo de AI com muitos dados (centenas de bilhÃµes de palavras ) obtemos um Large Language Model que Ã© a base do ChatGPT\\n\\nTransformers\\n\\nLLM Tokenization Byte Pair Encodng(BPE)\\n\\nhttps://tiktokenizer.vercel.app/\\n\\nLLM Playground\\n\\nhttps://colab.research.google.com/drive/1BKq_MMCcYz1eYLQaAenGJyuvxXoLeNQa?usp=sharing\\n\\nExerÃ­cios\\n\\nLer o primeiro capÃ­tulo do livro:\\n\\nhttps://hastie.su.domains/ISLP/ISLP_website.pdf.download.html\\n\\nE fazer o LAB de Python a partir da pÃ¡gina 40.')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3LNt54hXwVY"
      },
      "source": [
        "# Web Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWTYSml6X9R9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU3cPBcbYE8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f5822b3-0c35-4f9b-864c-4dbe68732ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split pdf into 0 sub-documents.\n"
          ]
        }
      ],
      "source": [
        "#fazendo o splitting dos documentos\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split pdf into {len(all_splits)} sub-documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyfQkCntYprV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694dc9aa-ec3b-4cb7-9f80-6193ff2be6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "#guardando os dados em um banco de dados\n",
        "document_ids = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "print(document_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AXIrueeY1md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8aacb6d-6820-45d2-f8a0-1c16e6403e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: (question goes here) \n",
            "Context: (context goes here) \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "## recuperando informaÃ§Ãµes para ajudar o chatgpt\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "example_messages = prompt.invoke(\n",
        "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
        ").to_messages()\n",
        "\n",
        "assert len(example_messages) == 1\n",
        "print(example_messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFEgavKNZCwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d38eaf-2917-4bb3-80fd-e9c9d346a06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: [Document(id='6fc79566-566b-480b-b1ad-46f9edae0c95', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 0}, page_content='Large Language\\n\\nmodels\\n\\nRegressÃ£o LogÃ­stica â€“ A funÃ§Ã£o SigmÃ³ide\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRegressÃ£o LogÃ­stica â€“ Algoritmo Gradiente descendente\\n\\nRegressÃ£o LogÃ­stica:\\n\\náˆ˜ğ‘“ ğ‘‹ = ğ‘(ğ‘¦|ğ‘‹)\\n\\nRedes Neurais\\n\\nEntrada\\n\\nSaÃ­da\\n\\nA escala move a IA\\n\\nQuanto mais camadas a rede neural\\n\\npossui, mais complexas as funÃ§Ãµes\\n\\nmatemÃ¡ticas que ela pode aprender...\\n\\nA escala move a IA\\n\\n...quanto mais complexa a rede\\n\\nneural, mais dados sÃ£o necessÃ¡rios\\n\\npara ela aprender.\\n\\nA escala move a IA\\n\\nGPT-4\\n\\nRede Neural com +200 bilhÃµes de parÃ¢metros(!)\\n\\nTreinados com mais de 53 trilhÃµes de palavras(!)\\n\\n+3 meses de treinamento dos modelos\\n\\nUm investimento total de mais de $63 milhÃµes (!)\\n\\nLLMs e IA\\n\\ngenerativa\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA'), Document(id='2b33026c-48fe-4432-8b69-ffc612f65907', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 821}, page_content='prompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nbolo\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nO que Ã© IA Generativa ? Pre-training\\n\\nProcesso geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano'), Document(id='0a52280c-12e8-4a0c-8992-04107bb60497', metadata={'source': '/content/Pastinha/Inteligencia_computacional_prompt_03 1.pdf', 'start_index': 1572}, page_content='Processo geraÃ§Ã£o de texto\\n\\nComo isso funciona na prÃ¡tica?\\n\\nEu adoro comer ____________\\n\\nprompt\\n\\nbolo de chocolate sanduÃ­che a comida da minha mÃ£e em restaurante italiano\\n\\nA aprendizado supervisionado para aprender a prever a prÃ³xima palavra repetidamente\\n\\nIA\\n\\ngenerativa\\n\\nutiliza\\n\\nEu adoro comer bolo de chocolate\\n\\nEntrada\\n\\nSaÃ­da\\n\\nResposta da IA\\n\\nEu adoro comer\\n\\nEu adoro comer bolo\\n\\nbolo\\n\\nde\\n\\nEu adoro comer bolo de\\n\\nchocolate\\n\\nQuando treinamos esse modelo de AI com muitos dados (centenas de bilhÃµes de palavras ) obtemos um Large Language Model que Ã© a base do ChatGPT\\n\\nTransformers\\n\\nLLM Tokenization Byte Pair Encodng(BPE)\\n\\nhttps://tiktokenizer.vercel.app/\\n\\nLLM Playground\\n\\nhttps://colab.research.google.com/drive/1BKq_MMCcYz1eYLQaAenGJyuvxXoLeNQa?usp=sharing\\n\\nExerÃ­cios\\n\\nLer o primeiro capÃ­tulo do livro:\\n\\nhttps://hastie.su.domains/ISLP/ISLP_website.pdf.download.html\\n\\nE fazer o LAB de Python a partir da pÃ¡gina 40.')]\n",
            "\n",
            "\n",
            "Answer: IA, ou InteligÃªncia Artificial, refere-se a sistemas computacionais capazes de realizar tarefas que normalmente requerem inteligÃªncia humana, como aprendizado, raciocÃ­nio e resoluÃ§Ã£o de problemas. Ela utiliza tÃ©cnicas como redes neurais e aprendizado supervisionado para processar grandes volumes de dados e gerar resultados. A IA generativa, por exemplo, Ã© um tipo de IA que cria conteÃºdo, como texto, com base em padrÃµes aprendidos.\n"
          ]
        }
      ],
      "source": [
        "result = graph.invoke({\"question\": \"O que Ã© IA?\"})\n",
        "\n",
        "print(f'Context: {result[\"context\"]}\\n\\n')\n",
        "print(f'Answer: {result[\"answer\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHLh_6GaZLHN"
      },
      "outputs": [],
      "source": [
        "result[\"context\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}